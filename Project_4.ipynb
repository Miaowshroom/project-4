{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) \n",
    "# Project 4: Web Scraping Job Postings\n",
    "\n",
    "## Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal has two main objectives:\n",
    "\n",
    "   1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "   2. Determine the factors that distinguish job categories and titles from each other. For example, can required skills accurately predict job title?\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries. \n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer these two questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job scrapping\n",
    "\n",
    "1. Job are scraped from mycareerfutures.sg\n",
    "2. Job searched with keyword data\n",
    "3. The job scrapping code can be found in the folder datajob\n",
    "4. Totally 4000+ jobs are scrapted\n",
    "5. To match the scope of the project, kept 1000+ jobs that can be determined as data related job from their job title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, HuberRegressor, LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from textblob import TextBlob\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_categories</th>\n",
       "      <th>job_experience</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_requirement</th>\n",
       "      <th>job_role_resp</th>\n",
       "      <th>job_salaries_max</th>\n",
       "      <th>job_salaries_min</th>\n",
       "      <th>job_salaries_type</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTT DATA SINGAPORE PTE. LTD.</td>\n",
       "      <td>Banking and Finance, Information Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manager, Professional</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/project-man...</td>\n",
       "      <td>KEPPEL TOWERS, 10 HOE CHIANG ROAD 089315</td>\n",
       "      <td>Project management,/Scrum Master/Business Anal...</td>\n",
       "      <td>We are looking for versatile project manager w...</td>\n",
       "      <td>$9,200</td>\n",
       "      <td>$7,500</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Budgets,Business Analysis,Business Development...</td>\n",
       "      <td>Project Manager- Data Security</td>\n",
       "      <td>Contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NTUC ENTERPRISE CO-OPERATIVE LTD</td>\n",
       "      <td>Education and Training, Information Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middle Management</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/vice-presid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Must be highly technical/strong hardware and s...</td>\n",
       "      <td>COMPANY DESCRIPTION,NTUC Enterprise is the hol...</td>\n",
       "      <td>$13,000</td>\n",
       "      <td>$8,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Business Analysis,Business Intelligence,Data A...</td>\n",
       "      <td>Vice President, Enterprise Data Warehouse</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIOFOURMIS SINGAPORE PTE. LTD.</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>https://www.mycareersfuture.sg/job/big-data-en...</td>\n",
       "      <td>VISION EXCHANGE, 2 VENTURE DRIVE 608526</td>\n",
       "      <td>~,Advanced working SQL knowledge and experienc...</td>\n",
       "      <td>We are looking for a savvy Data Engineer to jo...</td>\n",
       "      <td>$6,700</td>\n",
       "      <td>$5,200</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Agile Methodologies,C#,C++,HTML,Integration,Ja...</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Permanent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company_name  \\\n",
       "0      NTT DATA SINGAPORE PTE. LTD.   \n",
       "1  NTUC ENTERPRISE CO-OPERATIVE LTD   \n",
       "2    BIOFOURMIS SINGAPORE PTE. LTD.   \n",
       "\n",
       "                                   job_categories job_experience  \\\n",
       "0     Banking and Finance, Information Technology            NaN   \n",
       "1  Education and Training, Information Technology            NaN   \n",
       "2                                     Engineering            NaN   \n",
       "\n",
       "               job_level                                           job_link  \\\n",
       "0  Manager, Professional  https://www.mycareersfuture.sg/job/project-man...   \n",
       "1      Middle Management  https://www.mycareersfuture.sg/job/vice-presid...   \n",
       "2       Senior Executive  https://www.mycareersfuture.sg/job/big-data-en...   \n",
       "\n",
       "                               job_location  \\\n",
       "0  KEPPEL TOWERS, 10 HOE CHIANG ROAD 089315   \n",
       "1                                       NaN   \n",
       "2   VISION EXCHANGE, 2 VENTURE DRIVE 608526   \n",
       "\n",
       "                                     job_requirement  \\\n",
       "0  Project management,/Scrum Master/Business Anal...   \n",
       "1  Must be highly technical/strong hardware and s...   \n",
       "2  ~,Advanced working SQL knowledge and experienc...   \n",
       "\n",
       "                                       job_role_resp job_salaries_max  \\\n",
       "0  We are looking for versatile project manager w...           $9,200   \n",
       "1  COMPANY DESCRIPTION,NTUC Enterprise is the hol...          $13,000   \n",
       "2  We are looking for a savvy Data Engineer to jo...           $6,700   \n",
       "\n",
       "  job_salaries_min job_salaries_type  \\\n",
       "0           $7,500           Monthly   \n",
       "1           $8,000           Monthly   \n",
       "2           $5,200           Monthly   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0  Budgets,Business Analysis,Business Development...   \n",
       "1  Business Analysis,Business Intelligence,Data A...   \n",
       "2  Agile Methodologies,C#,C++,HTML,Integration,Ja...   \n",
       "\n",
       "                                   job_title   job_type  \n",
       "0             Project Manager- Data Security   Contract  \n",
       "1  Vice President, Enterprise Data Warehouse  Full Time  \n",
       "2                          Big Data Engineer  Permanent  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the job scraped from mycareerfuture.sg\n",
    "job_post = pd.read_csv('D:\\GA\\project_submission\\project-4\\datajob\\datajob\\datajob_0430_250pages.csv')\n",
    "job_post.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4013, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name           21\n",
       "job_categories          3\n",
       "job_experience       3752\n",
       "job_level              21\n",
       "job_link                0\n",
       "job_location          676\n",
       "job_requirement       108\n",
       "job_role_resp           0\n",
       "job_salaries_max        0\n",
       "job_salaries_min        0\n",
       "job_salaries_type       0\n",
       "job_skills              0\n",
       "job_title              18\n",
       "job_type               12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing data point\n",
    "job_post.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the data without title, without requirement of experience\n",
    "job_post.drop(index=job_post[job_post.job_title.isnull()].index, inplace=True)\n",
    "job_post.drop(index=job_post[job_post.job_level.isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name            3\n",
       "job_categories          0\n",
       "job_experience       3721\n",
       "job_level               0\n",
       "job_link                0\n",
       "job_location          662\n",
       "job_requirement        95\n",
       "job_role_resp           0\n",
       "job_salaries_max        0\n",
       "job_salaries_min        0\n",
       "job_salaries_type       0\n",
       "job_skills              0\n",
       "job_title               0\n",
       "job_type                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monthly     3852\n",
       "Annually     130\n",
       "Name: job_salaries_type, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post.job_salaries_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_post.job_salaries_min = job_post.job_salaries_min.map(lambda x: int(x[1:].replace(',', '')))\n",
    "job_post.job_salaries_max = job_post.job_salaries_max.map(lambda x: int(x[1:].replace(',', '')))\n",
    "\n",
    "job_post.loc[job_post.job_salaries_type=='Annually',['job_salaries_min', 'job_salaries_max']] = job_post.loc[job_post.job_salaries_type=='Annually',['job_salaries_min', 'job_salaries_max']]/12        \n",
    "job_post['job_salaries_mean'] = (job_post.job_salaries_min + job_post.job_salaries_max)/2\n",
    "job_post['job_salaries_range'] = (job_post.job_salaries_max - job_post.job_salaries_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post.drop_duplicates(keep='first', inplace=True)\n",
    "job_post.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3970, 16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_stop = list(ENGLISH_STOP_WORDS)\n",
    "title_stop.extend(['3000', '3500', '4000', 'days', 'contract', '1-year', 'orchard', \n",
    "                   'west', 'central', 'week', 'year','i2r','star', 'months','workday', \n",
    "                   'day', 'shift', 'ot', 'joo', 'koon', 'years','xaxis','workforce'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "# stemmer = PorterStemmer()\n",
    "# # lemmatized_title= job_post.job_title.map(lambda x: ' '.join([stemmer.stem(w) for w in TextBlob(x.lower()).words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=13,\n",
       "        ngram_range=(2, 3), preprocessor=None,\n",
       "        stop_words=['over', 'front', 'cannot', 'are', 'get', 'have', 're', 'sixty', 'when', 'of', 'noone', 'fire', 'before', 'formerly', 'indeed', 'do', 'down', 'itself', 'done', 'amongst', 'one', 'together', 'other', 'eleven', 'very', 'made', 'found', 'how', 'nevertheless', 'serious', 'whatever', 'yours', ...r', 'star', 'months', 'workday', 'day', 'shift', 'ot', 'joo', 'koon', 'years', 'xaxis', 'workforce'],\n",
       "        strip_accents=None, token_pattern='\\\\b[^\\\\d\\\\W_]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVect = CountVectorizer(ngram_range=(2,3), stop_words=title_stop, token_pattern=r'\\b[^\\d\\W_]+\\b', min_df=max(int(len(job_post)/300), 5))\n",
    "countVect.fit(job_post.job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "software engineer           96\n",
       "data scientist              89\n",
       "data engineer               82\n",
       "project manager             65\n",
       "business analyst            63\n",
       "research fellow             61\n",
       "data analyst                52\n",
       "product manager             49\n",
       "admin assistant             48\n",
       "senior manager              48\n",
       "data analytics              48\n",
       "account manager             48\n",
       "research engineer           45\n",
       "big data                    43\n",
       "accounts executive          41\n",
       "assistant manager           38\n",
       "senior software             36\n",
       "marketing manager           36\n",
       "t o                         36\n",
       "customer service            35\n",
       "research associate          34\n",
       "technology operations       32\n",
       "senior engineer             31\n",
       "network engineer            31\n",
       "accounts assistant          30\n",
       "senior executive            28\n",
       "research assistant          28\n",
       "senior data                 27\n",
       "operations executive        27\n",
       "software developer          26\n",
       "admin executive             25\n",
       "vice president              24\n",
       "senior software engineer    24\n",
       "business development        23\n",
       "key account                 23\n",
       "solution architect          23\n",
       "marketing executive         22\n",
       "senior research             22\n",
       "data science                22\n",
       "senior associate            22\n",
       "key account manager         21\n",
       "administrative assistant    21\n",
       "support engineer            21\n",
       "program manager             20\n",
       "information technology      19\n",
       "engineer senior             19\n",
       "senior consultant           19\n",
       "accounts officer            19\n",
       "river valley                19\n",
       "finance manager             19\n",
       "middle office               18\n",
       "engineer data               17\n",
       "sales admin                 17\n",
       "consumer banking            17\n",
       "operations manager          17\n",
       "development manager         17\n",
       "senior analyst              16\n",
       "human resource              16\n",
       "clinical research           16\n",
       "account executive           16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look of the high popular job key words\n",
    "pd.DataFrame(countVect.transform(job_post.job_title).todense(), columns=countVect.get_feature_names()).sum(axis=0).sort_values(ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post['job_label'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takindata_entryg all researchers\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('research'), 'job_label'] = 'Research'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take data scientist with the following keywords, if labeled before do not label again\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data scientist') & job_post.job_label.isnull(), 'job_label'] = 'data_scientist'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data science') & job_post.job_label.isnull(), 'job_label'] = 'data_scientist'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('machine learning') & job_post.job_label.isnull(), 'job_label'] = 'data_scientist'\n",
    "\n",
    "# data_scientist = pd.concat([data_scientist,job_post[job_post.job_title.str.lower().str.contains('data science')]])\n",
    "# data_scientist = pd.concat([data_scientist,job_post[job_post.job_title.str.lower().str.contains('machine learning')]])\n",
    "# data_scientist.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# # drop if this job is already in research\n",
    "# data_scientist.drop(index=[i for i in data_scientist.index if i in research.index], axis='index', inplace=True)\n",
    "# data_scientist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution architect \n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('architect') & job_post.job_label.isnull(), 'job_label'] = 'solution_architect'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('architecture') & job_post.job_label.isnull(), 'job_label'] = 'solution_architect'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('solution') & job_post.job_label.isnull(), 'job_label'] = 'solution_architect'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take data enginner with the following keywords\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data engineer') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data engineering') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data migration') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('security') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('cloud') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('system engineer') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('network engineer') & job_post.job_label.isnull(), 'job_label'] = 'data_engineer'\n",
    "\n",
    "\n",
    "\n",
    "# data_engineer = pd.concat([data_engineer,job_post[job_post.job_title.str.lower().str.contains('data engineering')]])\n",
    "# data_engineer = pd.concat([data_engineer,job_post[job_post.job_title.str.lower().str.contains('data migration')]])\n",
    "# data_engineer = pd.concat([data_engineer,job_post[job_post.job_title.str.lower().str.contains('security')]])\n",
    "# data_engineer = pd.concat([data_engineer,job_post[job_post.job_title.str.lower().str.contains('cloud')]])\n",
    "# data_engineer = pd.concat([data_engineer,job_post[job_post.job_title.str.lower().str.contains('system engineer')]])\n",
    "# data_engineer = pd.concat([data_engineer,job_post[job_post.job_title.str.lower().str.contains('network engineer')]])\n",
    "\n",
    "# data_engineer.drop_duplicates(keep='first', inplace=True)\n",
    "# data_engineer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take analyst job with the following keywords\n",
    "\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data analytics') & job_post.job_label.isnull(), 'job_label'] = 'data_analyst'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data analyst') & job_post.job_label.isnull(), 'job_label'] = 'data_analyst'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data analysis') & job_post.job_label.isnull(), 'job_label'] = 'data_analyst'\n",
    "\n",
    "# data_analyst = job_post[job_post.job_title.str.lower().str.contains('data analytics')]\n",
    "# data_analyst = pd.concat([data_analyst,job_post[job_post.job_title.str.lower().str.contains('data analyst')]])\n",
    "# data_analyst = pd.concat([data_analyst,job_post[job_post.job_title.str.lower().str.contains('data analysis')]])\n",
    "# data_analyst.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "\n",
    "# data_analyst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# taking all other analysis as other analyst\n",
    "\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('analyst') & job_post.job_label.isnull(), 'job_label'] = 'other_analyst'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('analysis') & job_post.job_label.isnull(), 'job_label'] = 'other_analyst'\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('analytics') & job_post.job_label.isnull(), 'job_label'] = 'other_analyst'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking all other analysis as other analyst\n",
    "job_post.loc[job_post.job_title.str.lower().str.contains('data entry') & job_post.job_label.isnull(), 'job_label'] = 'entry'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_analyst         288\n",
       "data_engineer         238\n",
       "Research              236\n",
       "solution_architect    123\n",
       "data_scientist        119\n",
       "data_analyst           81\n",
       "entry                  14\n",
       "Name: job_label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post.job_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_jobs = job_post[job_post.job_label.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_mean = q1_jobs.job_salaries_mean.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_mean_std = q1_jobs.job_salaries_mean.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_salary = [(salary_mean - salary_mean_std/2), (salary_mean + salary_mean_std/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4300.015609448624, 7699.984390551376]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q1_jobs['salary_cate'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_to_cate(x, middle_salary = middle_salary ):\n",
    "    if x<middle_salary[0]:\n",
    "        return 0\n",
    "    elif x<middle_salary[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "q1_jobs.salary_cate = q1_jobs.job_salaries_mean.map(salary_to_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    510\n",
       "2    322\n",
       "0    267\n",
       "Name: salary_cate, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_jobs.salary_cate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c399c1ef0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEyJJREFUeJzt3X9M1Pcdx/HXlwOC5Y4Q4h8LOhTbLkMNWwjRLrnaJl17Zq39YbCoC0uEddPZM3SxFRDRBmoxbP4D1f5I+49u6fzRNCZts60mhGBQFzNtYNctS9S2QJs62gg3z8P7fvdXb7UKdwfH3fm55+Ovct8Pd593JU+/fo8vWI7jOAIAGCcn3RsAAMwNAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGCo3HS++MqVK7VgwYKY68LhsPLz81Owo8zBzNkjG+dm5tkZHh7WmTNnYq5La+AXLFigd955J+a6QCCgioqKFOwoczBz9sjGuZl5dtauXRvXOi7RAIChCDwAGIrAA4ChCDwAGIrAA4Chpv0umsnJSbW0tGh4eFjhcFhbtmzR9773PW3evFmLFy+WJG3YsEE/+9nP1NPTo97eXuXm5qqlpUWVlZWp2D8AYArTBv7EiRMqLi5WV1eXvvrqKz311FPaunWrNm3apPr6+ui6oaEhnT17VkePHtXo6Kj8fr+OHz8+55sHAExt2sCvXr1aPp8v+rHL5dLg4KAuXryokydPatGiRWppadG5c+fk9XplWZZKS0sViUQ0NjamkpKSOR8AAHB70wa+sLBQkjQxMaFt27apsbFR4XBY69at0/Lly3Xw4EG98sor8ng8Ki4uvunzxsfHYwY+HA4rEAjE3GQoFIprnUmYOXtk49zMnBox72QdHR3V1q1btXHjRq1Zs0ZXr15VUVGRJOnhhx9We3u7HnroIQWDwejnBINBeTyemC+en58f151dyb7rLTQZUUGea8bHU4E7/bJHNs7NzKkxbeCvXLmi+vp6tbW16Sc/+YkkqaGhQbt27VJlZaUGBga0bNkyVVVVqaurSw0NDfr8889l23ZGX54pyHNpcdN7Ux6/1PloCncDAHNj2sC/+uqrunr1qg4cOKADBw5IkpqamrR3717l5eVp/vz5am9vl9vtVnV1tWpra2Xbttra2lKyeQDA1KYNfGtrq1pbW295/O23377lMb/fL7/fn7ydAQBmhRudAMBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBD5BocnIrI4DQKrE/I1OuBm/LATAnYIzeAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAENN+yv7Jicn1dLSouHhYYXDYW3ZskX33HOPmpqaZFmW7r33Xu3evVs5OTnq6elRb2+vcnNz1dLSosrKylTNAAC4jWkDf+LECRUXF6urq0tfffWVnnrqKf3whz9UY2OjVq5cqba2Np08eVKlpaU6e/asjh49qtHRUfn9fh0/fjxVMwAAbmPawK9evVo+ny/6scvl0tDQkFasWCFJWrVqlU6dOqXy8nJ5vV5ZlqXS0lJFIhGNjY2ppKRkbncPAJjStIEvLCyUJE1MTGjbtm1qbGzUvn37ZFlW9Pj4+LgmJiZUXFx80+eNj4/HDHw4HFYgEIi5yVAoFNe6eFVUVMRcM9XrzeZzE5Hsme8E2TizlJ1zM3NqTBt4SRodHdXWrVu1ceNGrVmzRl1dXdFjwWBQRUVFcrvdCgaDNz3u8Xhivnh+fn7cwYxnXTLN5vWSsdd0zJxu2TizlJ1zM3NqTPtdNFeuXFF9fb2ef/551dTUSJKWLl2qM2fOSJL6+vpUXV2tqqoq9ff3y7ZtjYyMyLZtLs8AQJpNewb/6quv6urVqzpw4IAOHDggSdq5c6c6Ojq0f/9+LVmyRD6fTy6XS9XV1aqtrZVt22pra0vJ5gEAU5s28K2trWptbb3l8cOHD9/ymN/vl9/vT97OAACzwo1OAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAg8AhiLwAGAoAn8boclIurcAALOWm+4NZKKCPJcWN71322OXOh9N8W4AYGY4gwcAQxF4ADAUgQcAQ8UV+AsXLqiurk6SNDQ0pPvvv191dXWqq6vT+++/L0nq6elRTU2N1q9fr48++mjudgwAiEvMN1nfeOMNnThxQvPmzZMk/eMf/9CmTZtUX18fXTM0NKSzZ8/q6NGjGh0dld/v1/Hjx+du1wCAmGKewZeVlam7uzv68eDgoHp7e/Xzn/9cLS0tmpiY0Llz5+T1emVZlkpLSxWJRDQ2NjanGwcATC/mGbzP59Nnn30W/biyslLr1q3T8uXLdfDgQb3yyivyeDwqLi6OriksLNT4+LhKSkqmfe5wOKxAIBBzk6FQKK518aqoqEjac91OMvaa7JnvBNk4s5SdczNzaiT8ffAPP/ywioqKov/d3t6uhx56SMFgMLomGAzK4/HEfK78/Py4YhsIBOY8ysmUjL3eaTMnQzbOLGXn3MycGgl/F01DQ0P0TdSBgQEtW7ZMVVVV6u/vl23bGhkZkW3bMc/eAQBzK+Ez+D179qi9vV15eXmaP3++2tvb5Xa7VV1drdraWtm2rba2trnYKwAgAXEFfuHChTpy5IgkadmyZXr77bdvWeP3++X3+5O7OwDAjHGjEwAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYKq7AX7hwQXV1dZKky5cva8OGDdq4caN2794t27YlST09PaqpqdH69ev10Ucfzd2OAQBxiRn4N954Q62trbp+/bok6eWXX1ZjY6P++Mc/ynEcnTx5UkNDQzp79qyOHj2q/fv368UXX5zzjWeq0GRkVscBIFlyYy0oKytTd3e3XnjhBUnS0NCQVqxYIUlatWqVTp06pfLycnm9XlmWpdLSUkUiEY2NjamkpGRud5+BCvJcWtz03pTHL3U+msLdAMhmMc/gfT6fcnP///eA4ziyLEuSVFhYqPHxcU1MTMjtdkfXfPM4ACB9Yp7Bf1dOzv//TggGgyoqKpLb7VYwGLzpcY/HE/O5wuGwAoFAzHWhUCiudfGqqKhI2nPNRDpmvhNk48xSds7NzKmRcOCXLl2qM2fOaOXKlerr69N9992nsrIydXV1qaGhQZ9//rls247r8kx+fn5csQ0EAmmPcrKEJiNTzhKajKggzyXJrJnjlY0zS9k5NzOnRsKB37Fjh3bt2qX9+/dryZIl8vl8crlcqq6uVm1trWzbVltb21zs1QjTXaPn+jyAZIor8AsXLtSRI0ckSeXl5Tp8+PAta/x+v/x+f3J3BwCYMW50AgBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMJSxgQ9NRtK9BQBIq9x0b2CuFOS5tLjpvdseu9T5aIp3AwCpZ+wZPABkOwJ/B4l12YnLUgC+zdhLNCaa7rKTxKUnADfjDB4ADEXgM8i3L7FUVFSkcScATMAlmgzCJRgAyTTjwD/55JPyeDySpIULF6q2tlYvvfSSXC6XvF6vnn322aRtEgCQuBkF/vr165KkQ4cORR974okn1N3dre9///v61a9+paGhIS1btiw5uwQAJGxG1+A//vhjXbt2TfX19frFL36hv/3tbwqHwyorK5NlWfJ6vRoYGEj2XgEACZjRGXxBQYEaGhq0bt06Xbp0Sc8884yKioqixwsLC/Xpp5/GfJ5wOKxAIBBzXSgUimvdt2Xrm5SJ/n/KJDP5czZBNs7NzKkxo8CXl5dr0aJFsixL5eXl8ng8+vrrr6PHg8HgTcGfSn5+flwhDgQCWRvsRN3J/5+y9c85G+dm5tSY0SWaY8eOqbOzU5L0xRdf6Nq1a7rrrrv0ySefyHEc9ff3q7q6OqkbBQAkZkZn8DU1NWpubtaGDRtkWZb27t2rnJwcbd++XZFIRF6vVz/60Y+SvVcAQAJmFPj8/Hz9/ve/v+XxI0eOzHpDAIDk4E5WADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgTdIaDIyo2MAzDSjX7qNzFSQ59Lipvdue+xS56Mp3g2AdOMMHpI4+wdMxBk8JHH2D5iIM3gAMBSBBwBD3bGB57owAEzvjr0GP901Y4nrxgBwx57BIzH8iwfIPnfsGTwSw794gOzDGTwAGIrAA4ChCDwAGIrAY9ZivYHLG7xAevAmK2aNN3CBzJTUM3jbttXW1qba2lrV1dXp8uXLyXx6pMlsz8D5QWZAeiT1DP7DDz9UOBzWn/70J50/f16dnZ06ePBgMl8CaTDbM3R+kBmQHkk9gz937pzuv/9+SdKPf/xjDQ4OJvPpYaBvn8FXVFRMe3w2zz2T48BsfPfr69tf36n62rMcx3GS9WQ7d+7UI488ogceeECS9OCDD+rDDz9Ubu7t/6GwcuVKLViwIFkvDwBZYXh4WGfOnIm5LqmXaNxut4LBYPRj27anjLukuDYIAJiZpF6iqaqqUl9fnyTp/Pnz+sEPfpDMpwcAJCCpl2hs29aePXv0r3/9S47jaO/evbr77ruT9fQAgAQkNfAAgMzBnawAYCgCDwCGytgfVfDN9fx//vOfys/PV0dHhxYtWpTubc3YhQsX9Lvf/U6HDh3S5cuX1dTUJMuydO+992r37t3KyclRT0+Pent7lZubq5aWFlVWVia0NpNMTk6qpaVFw8PDCofD2rJli+655x6j545EImptbdXFixflcrn08ssvy3Eco2f+xn/+8x+tXbtWb731lnJzc7Ni5ieffFIej0eStHDhQtXW1uqll16Sy+WS1+vVs88+O2XHzp8/H/faWXEy1J///Gdnx44djuM4zt///ndn8+bNad7RzL3++uvOY4895qxbt85xHMf59a9/7Zw+fdpxHMfZtWuX85e//MUZHBx06urqHNu2neHhYWft2rUJr80kx44dczo6OhzHcZyxsTHngQceMH7uv/71r05TU5PjOI5z+vRpZ/PmzcbP7DiOEw6Hnd/85jfOI4884vz73//OiplDoZDzxBNP3PTY448/7ly+fNmxbdv55S9/6QwODk7ZsUTWzkbGnsGbdFdsWVmZuru79cILL0iShoaGtGLFCknSqlWrdOrUKZWXl8vr9cqyLJWWlioSiWhsbCyhtSUlJWmb8btWr14tn88X/djlchk/909/+lM9+OCDkqSRkRHNnz9fvb29Rs8sSfv27dP69ev1+uuvS8qOr++PP/5Y165dU319vW7cuCG/369wOKyysjJJktfr1cDAgL788stbOjYxMRH32tnK2GvwExMTcrvd0Y9dLpdu3LiRxh3NnM/nu+mGL8dxZFmWJKmwsFDj4+O3zPvN44mszSSFhYVyu92amJjQtm3b1NjYmBVz5+bmaseOHWpvb5fP5zN+5nfeeUclJSXRMEnZ8fVdUFCghoYGvfnmm3rxxRfV3NysefPmRY9PNYvL5ZpyvrloXsaewSd6V+ydJCfn/3+vBoNBFRUV3TJvMBiUx+NJaG2mGR0d1datW7Vx40atWbNGXV1d0WMmz71v3z5t375dTz/9tK5fvx593MSZjx8/LsuyNDAwoEAgoB07dmhsbCx63MSZJam8vFyLFi2SZVkqLy+Xx+PR119/HT3+zSyhUOiWjt1uvqnWzrZ5GXsGb/JdsUuXLo3+mIa+vj5VV1erqqpK/f39sm1bIyMjsm1bJSUlCa3NJFeuXFF9fb2ef/551dTUSDJ/7nfffVevvfaaJGnevHmyLEvLly83euY//OEPOnz4sA4dOqSKigrt27dPq1atMnpmSTp27Jg6OzslSV988YWuXbumu+66S5988okcx1F/f390lu92zO12Ky8vL661s5WxNzqZdlfsZ599pt/+9rc6cuSILl68qF27dmlyclJLlixRR0eHXC6Xuru71dfXJ9u21dzcrOrq6oTWZpKOjg598MEHWrJkSfSxnTt3qqOjw9i5//vf/6q5uVlXrlzRjRs39Mwzz+juu+82/s/6G3V1ddqzZ49ycnKMnzkcDqu5uVkjIyOyLEvbt29XTk6O9u7dq0gkIq/Xq+eee27Kjp0/fz7utbORsYEHAMxOxl6iAQDMDoEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEP9D8a+AB/fgKzAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q1_jobs.job_salaries_mean.hist(bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1: Factors that impact salary\n",
    "\n",
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "You have learned a variety of new skills and models that may be useful for this problem:\n",
    "- NLP\n",
    "- Unsupervised learning and dimensionality reduction techniques (PCA, clustering)\n",
    "- Ensemble methods and decision tree models\n",
    "- SVM models\n",
    "\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to able to extrapolate or predict the expected salaries for these listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_name', 'job_categories', 'job_experience', 'job_level',\n",
       "       'job_link', 'job_location', 'job_requirement', 'job_role_resp',\n",
       "       'job_salaries_max', 'job_salaries_min', 'job_salaries_type',\n",
       "       'job_skills', 'job_title', 'job_type', 'job_salaries_mean',\n",
       "       'job_salaries_range', 'job_label', 'salary_cate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name             0\n",
       "job_categories           0\n",
       "job_experience        1033\n",
       "job_level                0\n",
       "job_link                 0\n",
       "job_location           198\n",
       "job_requirement         39\n",
       "job_role_resp            0\n",
       "job_salaries_max         0\n",
       "job_salaries_min         0\n",
       "job_salaries_type        0\n",
       "job_skills               0\n",
       "job_title                0\n",
       "job_type                 0\n",
       "job_salaries_mean        0\n",
       "job_salaries_range       0\n",
       "job_label                0\n",
       "salary_cate              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_jobs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choosen features are: job_categories, job_level, job_skills, job_label, job_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_salaries_max</th>\n",
       "      <th>job_salaries_min</th>\n",
       "      <th>job_salaries_mean</th>\n",
       "      <th>job_salaries_range</th>\n",
       "      <th>salary_cate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>2021.428571</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1760.714286</td>\n",
       "      <td>521.428571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>6653.735876</td>\n",
       "      <td>3886.539548</td>\n",
       "      <td>5270.137712</td>\n",
       "      <td>2767.196328</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_engineer</th>\n",
       "      <td>8346.158263</td>\n",
       "      <td>5210.840336</td>\n",
       "      <td>6778.499300</td>\n",
       "      <td>3135.317927</td>\n",
       "      <td>1.033613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_analyst</th>\n",
       "      <td>8381.728395</td>\n",
       "      <td>5288.135802</td>\n",
       "      <td>6834.932099</td>\n",
       "      <td>3093.592593</td>\n",
       "      <td>1.086420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_analyst</th>\n",
       "      <td>8396.829861</td>\n",
       "      <td>5359.280093</td>\n",
       "      <td>6878.054977</td>\n",
       "      <td>3037.549769</td>\n",
       "      <td>1.090278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_scientist</th>\n",
       "      <td>9782.408964</td>\n",
       "      <td>6132.997199</td>\n",
       "      <td>7957.703081</td>\n",
       "      <td>3649.411765</td>\n",
       "      <td>1.369748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solution_architect</th>\n",
       "      <td>11122.178862</td>\n",
       "      <td>6872.894309</td>\n",
       "      <td>8997.536585</td>\n",
       "      <td>4249.284553</td>\n",
       "      <td>1.593496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    job_salaries_max  job_salaries_min  job_salaries_mean  \\\n",
       "job_label                                                                   \n",
       "entry                    2021.428571       1500.000000        1760.714286   \n",
       "Research                 6653.735876       3886.539548        5270.137712   \n",
       "data_engineer            8346.158263       5210.840336        6778.499300   \n",
       "data_analyst             8381.728395       5288.135802        6834.932099   \n",
       "other_analyst            8396.829861       5359.280093        6878.054977   \n",
       "data_scientist           9782.408964       6132.997199        7957.703081   \n",
       "solution_architect      11122.178862       6872.894309        8997.536585   \n",
       "\n",
       "                    job_salaries_range  salary_cate  \n",
       "job_label                                            \n",
       "entry                       521.428571     0.000000  \n",
       "Research                   2767.196328     0.622881  \n",
       "data_engineer              3135.317927     1.033613  \n",
       "data_analyst               3093.592593     1.086420  \n",
       "other_analyst              3037.549769     1.090278  \n",
       "data_scientist             3649.411765     1.369748  \n",
       "solution_architect         4249.284553     1.593496  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_jobs.groupby(['job_label']).mean().sort_values(by='job_salaries_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer(object):\n",
    "    def __call__(self,s):\n",
    "        return  [WordNetLemmatizer().lemmatize(ele.strip()) for ele in s.split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_level_countVect = CountVectorizer(tokenizer=MyTokenizer(), analyzer='word', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 9)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_level_df= pd.DataFrame(job_level_countVect.fit_transform(q1_jobs.job_level).todense(),columns=job_level_countVect.get_feature_names() )\n",
    "job_level_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 8)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_level_dict =dict( zip(job_level_countVect.get_feature_names(),[3,0,2,6,7,1,5,4,8]))\n",
    "job_level_dict\n",
    "job_level_digit = q1_jobs.job_level.map(lambda x: \\\n",
    "                                        np.ceil(np.mean([job_level_dict[ele.strip().lower()] \\\n",
    "                                                       for ele in x.split(',') if ele.strip!=''])))\n",
    "job_level_df = pd.get_dummies(job_level_digit)\n",
    "job_level_df = job_level_df.drop(columns=[0])\n",
    "job_level_df.reset_index(drop=True, inplace=True)\n",
    "job_level_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cate_countVect = TfidfVectorizer(tokenizer=MyTokenizer(), analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_cate_df= pd.DataFrame(job_cate_countVect.fit_transform(q1_jobs.job_categories).todense(),columns=job_cate_countVect.get_feature_names() )\n",
    "job_cate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_skill_countVect = TfidfVectorizer(tokenizer=MyTokenizer(), analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 761)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_skill_df= pd.DataFrame(job_skill_countVect.fit_transform(q1_jobs.job_skills).todense(),columns=job_skill_countVect.get_feature_names() )\n",
    "job_skill_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type_countVect = CountVectorizer(tokenizer=MyTokenizer(), analyzer='word', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 8)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_type_df= pd.DataFrame(job_type_countVect.fit_transform(q1_jobs.job_type).todense(),columns=job_type_countVect.get_feature_names() )\n",
    "job_type_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_label_df = pd.get_dummies(q1_jobs.job_label)\n",
    "job_label_df = job_label_df.drop(columns=['entry'])\n",
    "job_label_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 6)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([job_level_df, job_cate_df, job_skill_df,job_type_df, job_label_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 815)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = q1_jobs.salary_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        97\n",
      "           1       0.64      0.69      0.66       157\n",
      "           2       0.59      0.52      0.56       109\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       363\n",
      "   macro avg       0.66      0.66      0.66       363\n",
      "weighted avg       0.66      0.66      0.66       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "logR = LogisticRegressionCV(class_weight='balanced', penalty='l2', max_iter=5000 , cv=5)\n",
    "scaler = StandardScaler()\n",
    "X_train_ss = scaler.fit_transform(X_train)\n",
    "logR.fit(X_train_ss, y_train)\n",
    "X_test_ss = scaler.transform(X_test)\n",
    "y_pred = logR.predict(X_test_ss)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       123\n",
      "           1       0.56      0.55      0.55       152\n",
      "           2       0.49      0.55      0.52        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       363\n",
      "   macro avg       0.58      0.59      0.58       363\n",
      "weighted avg       0.59      0.59      0.59       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "logR = LogisticRegressionCV(class_weight='balanced', penalty='l2', max_iter=5000 , cv=5)\n",
    "scaler = StandardScaler()\n",
    "X_train_ss = scaler.fit_transform(X_train)\n",
    "logR.fit(X_train_ss, y_train)\n",
    "X_test_ss = scaler.transform(X_test)\n",
    "y_pred = logR.predict(X_test_ss)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.61        97\n",
      "           1       0.54      0.75      0.63       157\n",
      "           2       0.64      0.45      0.53       109\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       363\n",
      "   macro avg       0.64      0.58      0.59       363\n",
      "weighted avg       0.62      0.60      0.60       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "cross_val_score(MNB, X_train, y_train, cv=10)\n",
    "MNB.fit(X_train, y_train)\n",
    "y_pred = MNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63       123\n",
      "           1       0.48      0.52      0.50       152\n",
      "           2       0.49      0.53      0.51        88\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       363\n",
      "   macro avg       0.56      0.55      0.55       363\n",
      "weighted avg       0.56      0.55      0.55       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "cross_val_score(MNB, X_train, y_train, cv=10)\n",
    "MNB.fit(X_train, y_train)\n",
    "y_pred = MNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1537 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1987 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:  1.6min finished\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71        97\n",
      "           1       0.58      0.85      0.69       157\n",
      "           2       0.78      0.39      0.52       109\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       363\n",
      "   macro avg       0.72      0.63      0.64       363\n",
      "weighted avg       0.70      0.66      0.64       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imb_pipleine = imPipeline([('smt', SMOTE()), ('estimator',RandomForestClassifier())])\n",
    "parameter = {\n",
    "    'smt__k_neighbors': range(3,7),\n",
    "    'smt__sampling_strategy': ['minority'],\n",
    "    'estimator__n_estimators': [10, 15, 20, 50, 100],\n",
    "    'estimator__max_depth': [10, 15, 30, 60, 100],\n",
    "    'estimator__min_samples_split': [20, 10, 6, 4, 2]\n",
    "}\n",
    "\n",
    "imb_pipleine_gs = GridSearchCV(imb_pipleine, parameter,scoring='f1_micro' ,cv=5, verbose=1, n_jobs=-1)\n",
    "imb_pipleine_gs.fit(X_train, y_train)\n",
    "y_pred = imb_pipleine_gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.59      0.69       123\n",
      "           1       0.58      0.61      0.59       152\n",
      "           2       0.43      0.56      0.49        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       363\n",
      "   macro avg       0.61      0.59      0.59       363\n",
      "weighted avg       0.62      0.59      0.60       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:  1.6min finished\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "imb_pipleine = imPipeline([('smt', SMOTE()), ('estimator',RandomForestClassifier())])\n",
    "parameter = {\n",
    "    'smt__k_neighbors': range(3,7),\n",
    "    'smt__sampling_strategy': ['minority'],\n",
    "    'estimator__n_estimators': [10, 15, 20, 50, 100],\n",
    "    'estimator__max_depth': [10, 15, 30, 60, 100],\n",
    "    'estimator__min_samples_split': [20, 10, 6, 4, 2]\n",
    "}\n",
    "\n",
    "imb_pipleine_gs = GridSearchCV(imb_pipleine, parameter,scoring='f1_micro' ,cv=5, verbose=1, n_jobs=-1)\n",
    "imb_pipleine_gs.fit(X_train, y_train)\n",
    "y_pred = imb_pipleine_gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 245 candidates, totalling 1225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 390 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 990 tasks      | elapsed:   56.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72        97\n",
      "           1       0.62      0.70      0.66       157\n",
      "           2       0.66      0.62      0.64       109\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       363\n",
      "   macro avg       0.69      0.66      0.67       363\n",
      "weighted avg       0.68      0.67      0.67       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1225 out of 1225 | elapsed:  1.2min finished\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf_parameter = {'n_estimators': [10, 15, 20, 50,100, 200, 300],\n",
    "                'max_depth': [10, 15, 30, 60, 100, 200, 400],\n",
    "                'min_samples_split': [20, 10, 6, 4, 2]\n",
    "  \n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(rf, rf_parameter,scoring='f1_micro' ,cv=5, n_jobs=-1, verbose=1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "y_pred = rf_gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 245 candidates, totalling 1225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 412 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 662 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1225 out of 1225 | elapsed:  1.2min finished\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf_parameter = {'n_estimators': [10, 15, 20, 50,100, 200, 300],\n",
    "                'max_depth': [10, 15, 30, 60, 100, 200, 400],\n",
    "                'min_samples_split': [20, 10, 6, 4, 2]\n",
    "  \n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(rf, rf_parameter,scoring='f1_micro' ,cv=5, n_jobs=-1, verbose=1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "y_pred = rf_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.69       123\n",
      "           1       0.58      0.57      0.57       152\n",
      "           2       0.48      0.55      0.51        88\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       363\n",
      "   macro avg       0.60      0.59      0.59       363\n",
      "weighted avg       0.60      0.60      0.60       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 57.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 101.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 113.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 134.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 158.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 183.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 212.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10935 out of 10935 | elapsed: 234.9min finished\n",
      "C:\\Users\\huwenmiao\\Anaconda3\\envs\\gadsi36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76        97\n",
      "           1       0.62      0.71      0.66       157\n",
      "           2       0.67      0.62      0.64       109\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       363\n",
      "   macro avg       0.70      0.68      0.69       363\n",
      "weighted avg       0.69      0.68      0.68       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imb_pipleine = imPipeline([('smt', SMOTE()), ('estimator',GradientBoostingClassifier())])\n",
    "\n",
    "parameter = {\n",
    "    'estimator__learning_rate': [0.1, 0.5, 1],\n",
    "    'estimator__max_depth': [20, 50, 70],\n",
    "    'estimator__max_features': ['auto', 'log2', 0.4],\n",
    "    'estimator__max_leaf_nodes': [3, 5, 10 ],\n",
    "    'estimator__min_samples_leaf': [1,3, 5],\n",
    "    'estimator__min_samples_split': [2, 4, 6],\n",
    "    'estimator__n_estimators': [ 10, 50, 100]\n",
    "}\n",
    "\n",
    "imb_pipleine_gs = GridSearchCV(imb_pipleine, parameter,scoring='f1_micro' ,cv=5, n_jobs=-1, verbose=1)\n",
    "imb_pipleine_gs.fit(X_train, y_train)\n",
    "y_pred = imb_pipleine_gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('3class_xgb.p', 'wb') as f:\n",
    "#     pickle.dump(imb_pipleine_gs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('3class_xgb.p', 'rb') as f:\n",
    "#     imb_pipleine_gs2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   45.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74       123\n",
      "           1       0.60      0.64      0.62       152\n",
      "           2       0.57      0.57      0.57        88\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       363\n",
      "   macro avg       0.65      0.64      0.64       363\n",
      "weighted avg       0.65      0.65      0.65       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imb_pipleine = imPipeline([('smt', SMOTE()), ('estimator',GradientBoostingClassifier())])\n",
    "\n",
    "parameter = {\n",
    "    'estimator__learning_rate': [0.1, 0.01, 0.5, 1],\n",
    "#     'estimator__loss': ['deviance', 'exponential'],\n",
    "#     'estimator__max_depth': [3,4,5],\n",
    "#     'estimator__max_features': ['auto', 'log2', 0.4],\n",
    "#     'estimator__max_leaf_nodes': [3, 9, 20],\n",
    "#     'estimator__min_samples_leaf': [1,2,3],\n",
    "#     'estimator__min_samples_split': [2,3,4],\n",
    "#     'estimator__n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "imb_pipleine_gs = GridSearchCV(imb_pipleine, parameter,scoring='f1_micro' ,cv=5, n_jobs=-1, verbose=1)\n",
    "imb_pipleine_gs.fit(X_train, y_train)\n",
    "y_pred = imb_pipleine_gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "- Do the requirements for titles vary significantly with industry (e.g. healthcare vs. government)?\n",
    "\n",
    "You may end up making multiple classification models to tackle different questions. Be sure to clearly explain your hypotheses and framing, any feature engineering, and what your target variables are. The type of classification model you choose is up to you. Be sure to interpret your results and evaluate your models' performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
